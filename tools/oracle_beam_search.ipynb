{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Metadata Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from pcdet.models import build_network, load_data_to_gpu\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.utils import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs and checkpoints for all branches\n",
    "branches = [['cfgs/waymo_models/centerpoint_dyn_pillar020_1x.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_pillar020_1x.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_pillar024_1x.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_pillar024_1x.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_pillar028_1x.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_pillar028_1x.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_pillar032_1x.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_pillar032_1x.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_pillar036_1x.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_pillar036_1x.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_pillar040_1x.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_pillar040_1x.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_voxel0075.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_voxel0075.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_voxel0100.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_voxel0100.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_voxel0125.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_voxel0125.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_voxel0150.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_voxel0150.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_voxel0175.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_voxel0175.pth'],\n",
    "            ['cfgs/waymo_models/centerpoint_dyn_voxel0200.yaml',\n",
    "                '../output/waymo_checkpoints/centerpoint_dyn_voxel0200.pth']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate look up table for Content Agnostic Scheduler\n",
    "# Accuracy (mAP) of each branch on the test set\n",
    "# Average Latency of each branch on the test set\n",
    "import numpy as np\n",
    "\n",
    "# Get accuracy profiling results of all branches\n",
    "# Level1 mAP of 3 classes: Vehicle, pedestrian, cyclist\n",
    "acc_test = [0.708, 0.7075, 0.7048, 0.6948, 0.694, 0.6809, 0.7399, 0.7168, 0.6912, 0.6588, 0.6321, 0.5964]\n",
    "# acc_val = [0.7512, 0.7437, 0.7428, 0.7333, 0.7289, 0.7179, 0.7805, 0.7636, 0.7383, 0.7060, 0.6775, 0.6712]\n",
    "\n",
    "# Get latency profiling results of all branches \n",
    "lat_orin_test = np.load('../output/waymo_results/latency_profiling/test/latency_profiling_test.npy', allow_pickle=True)\n",
    "#lat_orin_val = np.load('../output/waymo_results/latency_profiling/val/latency_profiling_val.npy', allow_pickle=True)\n",
    "\n",
    "lat = []\n",
    "for i, res in enumerate(lat_orin_test):\n",
    "    e2e = (round(np.float64(lat_orin_test[i][1]), 2))\n",
    "    lat.append(e2e)\n",
    "print(lat)\n",
    "\n",
    "look_up_content_ag = []\n",
    "for i in range(len(lat)):\n",
    "    look_up_content_ag.append([i, lat[i], acc_test[i]])\n",
    "print(look_up_content_ag)\n",
    "# np.save('look_up_content_ag_orin_waymo', look_up_content_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[0, 449.85, 0.708], [1, 303.97, 0.7075], [2, 234.55, 0.7048], [3, 174.38, 0.6948], [4, 156.61, 0.694], [5, 135.58, 0.6809], [6, 235.76, 0.7399], [7, 169.42, 0.7168], [8, 146.25, 0.6912], [9, 122.81, 0.6588], [10, 110.08, 0.6321], [11, 100.87, 0.5964]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "# Baseline results\n",
    "baselines = ['centerpoint_pillar_1x',\n",
    "            'centerpoint_without_resnet',\n",
    "            'second',\n",
    "            'PartA2',\n",
    "            'pointpillar_1x',\n",
    "            'pv_rcnn']\n",
    "\n",
    "data_root = '../output/waymo_results'\n",
    "# latency profiles\n",
    "print('Loading baseline latency for test samples...')\n",
    "lat_dir = os.path.join(data_root, 'baselines')\n",
    "branch_lats = []\n",
    "for b in baselines:\n",
    "    lat_path = os.path.join(lat_dir, b + '_lat.pkl')\n",
    "    lat = pickle.load(open(lat_path, 'rb'))\n",
    "    branch_lats.append(np.array(lat))\n",
    "branch_lats = np.stack(branch_lats, axis=-1)    # (#samples, #branches)\n",
    "print(branch_lats.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(branch_lats.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "# Oracle controller\n",
    "branches = ['centerpoint_dyn_pillar024_4x',\n",
    "            'centerpoint_dyn_pillar028_4x',\n",
    "            'centerpoint_dyn_pillar032_4x',\n",
    "            'centerpoint_dyn_pillar036_4x',\n",
    "            'centerpoint_dyn_pillar040_4x',\n",
    "            'centerpoint_dyn_pillar044_4x',\n",
    "            'centerpoint_dyn_pillar048_4x',\n",
    "            'centerpoint_dyn_pillar052_4x',\n",
    "            'centerpoint_without_resnet_dyn_voxel100',\n",
    "            'centerpoint_without_resnet_dyn_voxel150',\n",
    "            'centerpoint_without_resnet_dyn_voxel200',\n",
    "            'centerpoint_without_resnet_dyn_voxel250',\n",
    "            'centerpoint_without_resnet_dyn_voxel300',\n",
    "            'centerpoint_without_resnet_dyn_voxel350',\n",
    "            'centerpoint_without_resnet_dyn_voxel400',\n",
    "            'centerpoint_without_resnet_dyn_voxel450',\n",
    "            'dsvt_sampled_pillar020',\n",
    "            'dsvt_sampled_pillar030',\n",
    "            'dsvt_sampled_pillar040',\n",
    "            'dsvt_sampled_pillar050',\n",
    "            'dsvt_sampled_pillar060',\n",
    "            'dsvt_sampled_pillar070',\n",
    "            'dsvt_sampled_pillar080',\n",
    "            'dsvt_sampled_pillar090',\n",
    "            'dsvt_sampled_pillar100',\n",
    "            'dsvt_sampled_pillar110',\n",
    "            'dsvt_sampled_pillar120',\n",
    "            'dsvt_sampled_pillar130',\n",
    "            'dsvt_sampled_voxel020',\n",
    "            'dsvt_sampled_voxel030',\n",
    "            'dsvt_sampled_voxel040',\n",
    "            'dsvt_sampled_voxel050',\n",
    "            'dsvt_sampled_voxel060',\n",
    "            'dsvt_sampled_voxel070',\n",
    "            'dsvt_sampled_voxel080',\n",
    "            'dsvt_sampled_voxel090',\n",
    "            'dsvt_sampled_voxel100',\n",
    "            'dsvt_sampled_voxel110',\n",
    "            'dsvt_sampled_voxel120',\n",
    "            'dsvt_sampled_voxel130']\n",
    "\n",
    "data_root = '../output/waymo_new_profiling'\n",
    "\n",
    "# latency profiles\n",
    "print('Loading branch latency for test samples...')\n",
    "lat_dir = os.path.join(data_root, 'lat/test')\n",
    "branch_lats = []\n",
    "for b in branches:\n",
    "    lat_path = os.path.join(lat_dir, b + '_lat.pkl')\n",
    "    lat = pickle.load(open(lat_path, 'rb'))\n",
    "    branch_lats.append(np.array(lat))\n",
    "branch_lats = np.stack(branch_lats, axis=-1)    # (#samples, #branches)\n",
    "\n",
    "# accuracy profiles in waymo format\n",
    "print('Loading branch accuracy for test samples...')\n",
    "branch_accs = np.load('../output/waymo_new_profiling/per_frame_l2_acc_test.npy', allow_pickle=True)\n",
    "\n",
    "# acc_dir = os.path.join(data_root, '../output/waymo_new_profiling/per_frame_acc/test')\n",
    "# branch_accs = []\n",
    "# for b in branches:\n",
    "#     acc_path = os.path.join(acc_dir, b + '_per_frame_test.txt')\n",
    "#     with open(acc_path, \"r\") as file:\n",
    "#         content = file.read()\n",
    "#     pattern = r'\\b\\d+\\.\\d+\\b'\n",
    "#     result = [[float(match) for match in re.findall(pattern, line)] for line in content.split(\"{\")[1:]]\n",
    "#     # indices = [0, 4, 12]\n",
    "#     indices = [2, 6, 14]\n",
    "#     acc = [sum(item[index] for index in indices) / len(indices) for item in result]\n",
    "#     branch_accs.append(np.array(acc))\n",
    "# branch_accs = np.stack(branch_accs, axis=-1)    # (#samples, #branches)\n",
    "\n",
    "# # accuracy profiles in kitti format\n",
    "# print('Loading branch accuracy for test samples...')\n",
    "# acc_dir = os.path.join(data_root, 'accuracy_profiling/kitti_format/test')\n",
    "# branch_accs = []\n",
    "# for b in branches:\n",
    "#     acc_path = os.path.join(acc_dir, b + '_kitti.txt')\n",
    "#     with open(acc_path, \"r\") as file:\n",
    "#         acc = file.readlines()\n",
    "#     acc_values = [float(line.strip()) for line in acc]\n",
    "#     branch_accs.append(np.array(acc_values))\n",
    "# branch_accs = np.stack(branch_accs, axis=-1)    # (#samples, #branches)\n",
    "\n",
    "\n",
    "# load detection profiles\n",
    "print('Loading branch detection results for test samples...')\n",
    "det_dir = os.path.join(data_root, 'det/test')\n",
    "branch_profiles = []\n",
    "for b in branches:\n",
    "    det_path = os.path.join(det_dir, b + '_det.pkl')\n",
    "    det = pickle.load(open(det_path, 'rb'))\n",
    "    branch_profiles.append(det)\n",
    "branch_profiles = np.stack(branch_profiles, axis=-1)    # (#samples, #branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('latency.npy', branch_lats)\n",
    "np.save('accuracy.npy', branch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(branch_profiles)\n",
    "print(branch_profiles.shape)\n",
    "print(len(branch_profiles))\n",
    "print(len(branch_profiles[0]))\n",
    "# print(branch_profiles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(branch_accs)\n",
    "print(branch_accs.shape)\n",
    "print(len(branch_accs))\n",
    "print(len(branch_accs[0]))\n",
    "print(branch_accs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(branch_lats)\n",
    "print(branch_lats.shape)\n",
    "print(len(branch_lats))\n",
    "print(len(branch_lats[0]))\n",
    "print(branch_lats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latency budgets\n",
    "board = 'orin'\n",
    "slo_list = (50, 100, 150, 200, 250, 300, 350, 400, 450, 500)\n",
    "# slo_list = (1000, 2000)\n",
    "schd_overhead = 0\n",
    "\n",
    "# SWITCH BETWEEN LATENCY PREDICTORS AND THRESHOLDS\n",
    "print('Running virtual branch scheduling...')\n",
    "det_results, lat_results = dict(), dict()\n",
    "for slo in slo_list:\n",
    "    det_results[slo] = []\n",
    "    lat_results[slo] = []\n",
    "\n",
    "# k is the number of frames\n",
    "for k in range(len(branch_lats)):\n",
    "    if (k + 1) % 500 == 0:\n",
    "        print(f'{(k + 1):04d} done!')\n",
    "\n",
    "    # for each frame, load the lat and acc of 20 branches\n",
    "    lat, acc = branch_lats[k], branch_accs[k]\n",
    "\n",
    "    for slo in slo_list:\n",
    "        # Filter valid branches according to the latency slo\n",
    "        valid_branches = np.nonzero(lat + schd_overhead <= slo)[0]\n",
    "        # If there is no valid branch, choose the fastest branch\n",
    "        if len(valid_branches) == 0:\n",
    "            valid_branches = [lat.argmin()]\n",
    "        # Select the branch come with the highest acc\n",
    "        # If multiple branches have the same highest acc, choose the fastest branch\n",
    "        sorted_indices = np.lexsort((lat[valid_branches], -acc[valid_branches]))\n",
    "        b = valid_branches[sorted_indices[0]]\n",
    "        lat_results[slo].append(lat[b])\n",
    "\n",
    "        # load detection profile\n",
    "        det = branch_profiles[k][b]\n",
    "        det_results[slo].append(det)\n",
    "\n",
    "print('Saving detection results...')\n",
    "out_dir = '../output/oracle/oracle'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for slo in slo_list:\n",
    "    out_path = os.path.join(out_dir, f'{board}_slo{slo:d}_oracle.pkl')\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(det_results[slo], f)\n",
    "\n",
    "    lat = np.array(lat_results[slo]).mean()\n",
    "    print(f\"Latency [SLO: {slo:d}]: {lat:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading branch latency for test samples...\n",
      "Loading branch accuracy for test samples...\n",
      "Running virtual branch scheduling...\n",
      "5000 done!\n",
      "10000 done!\n",
      "15000 done!\n",
      "20000 done!\n",
      "25000 done!\n",
      "30000 done!\n",
      "35000 done!\n",
      "Saving branch ranking results...\n",
      "Latency [SLO: 50]: 43.71s\n",
      "Latency [SLO: 100]: 75.34s\n",
      "Latency [SLO: 150]: 107.86s\n",
      "Latency [SLO: 200]: 139.37s\n",
      "Latency [SLO: 250]: 161.85s\n",
      "Latency [SLO: 300]: 177.49s\n",
      "Latency [SLO: 350]: 192.40s\n",
      "Latency [SLO: 400]: 203.25s\n",
      "Latency [SLO: 450]: 211.48s\n",
      "Latency [SLO: 500]: 216.97s\n",
      "Latency [SLO: 5000]: 264.41s\n"
     ]
    }
   ],
   "source": [
    "# visualize the ranking of all branches\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "# Oracle controller\n",
    "branches = ['centerpoint_dyn_pillar052_4x',\n",
    "            'centerpoint_dyn_pillar048_4x',\n",
    "            'centerpoint_dyn_pillar044_4x',\n",
    "            'centerpoint_dyn_pillar040_4x',\n",
    "            'centerpoint_dyn_pillar036_4x',\n",
    "            'centerpoint_dyn_pillar032_4x',\n",
    "            'centerpoint_dyn_pillar028_4x',\n",
    "            'centerpoint_dyn_pillar024_4x',\n",
    "            'centerpoint_without_resnet_dyn_voxel450',\n",
    "            'centerpoint_without_resnet_dyn_voxel400',\n",
    "            'centerpoint_without_resnet_dyn_voxel350',\n",
    "            'centerpoint_without_resnet_dyn_voxel300',\n",
    "            'centerpoint_without_resnet_dyn_voxel250',\n",
    "            'centerpoint_without_resnet_dyn_voxel200',\n",
    "            'centerpoint_without_resnet_dyn_voxel150',\n",
    "            'centerpoint_without_resnet_dyn_voxel100',\n",
    "            'dsvt_sampled_pillar130',\n",
    "            'dsvt_sampled_pillar120',\n",
    "            'dsvt_sampled_pillar110',\n",
    "            'dsvt_sampled_pillar100',\n",
    "            'dsvt_sampled_pillar090',\n",
    "            'dsvt_sampled_pillar080',\n",
    "            'dsvt_sampled_pillar070',\n",
    "            'dsvt_sampled_pillar060',\n",
    "            'dsvt_sampled_pillar050',\n",
    "            'dsvt_sampled_pillar040',\n",
    "            'dsvt_sampled_pillar030',\n",
    "            'dsvt_sampled_pillar020',\n",
    "            'dsvt_sampled_voxel130',\n",
    "            'dsvt_sampled_voxel120',\n",
    "            'dsvt_sampled_voxel110',\n",
    "            'dsvt_sampled_voxel100',\n",
    "            'dsvt_sampled_voxel090',\n",
    "            'dsvt_sampled_voxel080',\n",
    "            'dsvt_sampled_voxel070',\n",
    "            'dsvt_sampled_voxel060',\n",
    "            'dsvt_sampled_voxel050',\n",
    "            'dsvt_sampled_voxel040',\n",
    "            'dsvt_sampled_voxel030',\n",
    "            'dsvt_sampled_voxel020']\n",
    "\n",
    "data_root = '../output/waymo_new_profiling'\n",
    "\n",
    "# latency profiles\n",
    "print('Loading branch latency for test samples...')\n",
    "lat_dir = os.path.join(data_root, 'lat/test')\n",
    "branch_lats = []\n",
    "for b in branches:\n",
    "    lat_path = os.path.join(lat_dir, b + '_lat.pkl')\n",
    "    lat = pickle.load(open(lat_path, 'rb'))\n",
    "    branch_lats.append(np.array(lat))\n",
    "branch_lats = np.stack(branch_lats, axis=-1)    # (#samples, #branches)\n",
    "\n",
    "# accuracy profiles in waymo format\n",
    "print('Loading branch accuracy for test samples...')\n",
    "branch_accs = np.load('../output/waymo_new_profiling/per_frame_l2_acc_test.npy', allow_pickle=True)\n",
    "\n",
    "# ========================================================================================================\n",
    "# latency budgets\n",
    "board = 'orin'\n",
    "slo_list = (50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 5000)\n",
    "# slo_list = (1000, 2000)\n",
    "schd_overhead = 0\n",
    "\n",
    "# SWITCH BETWEEN LATENCY PREDICTORS AND THRESHOLDS\n",
    "print('Running virtual branch scheduling...')\n",
    "branch_results, lat_results = dict(), dict()\n",
    "for slo in slo_list:\n",
    "    branch_results[slo] = []\n",
    "    lat_results[slo] = []\n",
    "\n",
    "# k is the number of frames\n",
    "for k in range(len(branch_lats)):\n",
    "    if (k + 1) % 5000 == 0:\n",
    "        print(f'{(k + 1):04d} done!')\n",
    "\n",
    "    # for each frame, load the lat and acc of 20 branches\n",
    "    lat, acc = branch_lats[k], branch_accs[k]\n",
    "\n",
    "    for slo in slo_list:\n",
    "        # Filter valid branches according to the latency slo\n",
    "        valid_branches = np.nonzero(lat + schd_overhead <= slo)[0]\n",
    "        # If there is no valid branch, choose the fastest branch\n",
    "        if len(valid_branches) == 0:\n",
    "            valid_branches = [lat.argmin()]\n",
    "        # Select the branch come with the highest acc\n",
    "        # If multiple branches have the same highest acc, choose the fastest branch\n",
    "        sorted_indices = np.lexsort((lat[valid_branches], -acc[valid_branches]))\n",
    "        b = valid_branches[sorted_indices[0]]\n",
    "        lat_results[slo].append(lat[b])\n",
    "\n",
    "        # save branch selection\n",
    "        branch_results[slo].append(sorted_indices)\n",
    "\n",
    "print('Saving branch ranking results...')\n",
    "out_dir = '../output/oracle/oracle'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for slo in slo_list:\n",
    "    out_path = os.path.join(out_dir, f'{board}_slo{slo:d}_oracle_branch_ranking.pkl')\n",
    "    with open(out_path, 'wb') as f:\n",
    "        pickle.dump(branch_results[slo], f)\n",
    "\n",
    "    lat = np.array(lat_results[slo]).mean()\n",
    "    print(f\"Latency [SLO: {slo:d}]: {lat:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming the 178x40 data is sorted from best (low values) to worst (high values) for each of the 178 dimensions\n",
    "# Simulating data: For demonstration, generating random data\n",
    "np.random.seed(0)\n",
    "data = np.random.rand(178, 40)\n",
    "\n",
    "# Sorting each of the 178 dimensions (rows) from best to worst\n",
    "data_sorted = np.sort(data, axis=1)\n",
    "\n",
    "# Creating a heatmap\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(data_sorted, cmap='coolwarm', cbar_kws={'label': 'Ranking (Low to High)'})\n",
    "plt.title('Heatmap of Rankings Across 178 Branches')\n",
    "plt.xlabel('Branch Index')\n",
    "plt.ylabel('Rank')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(branch_results[5000][0:198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (198,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(branch_results[500][:178])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq_4_slo200_ranking.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbranch_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m793\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m991\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_3_slo200_ranking.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, branch_results[\u001b[38;5;241m200\u001b[39m][\u001b[38;5;241m595\u001b[39m:\u001b[38;5;241m793\u001b[39m])\n\u001b[1;32m      4\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq_2_slo200_ranking.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, branch_results[\u001b[38;5;241m200\u001b[39m][\u001b[38;5;241m397\u001b[39m:\u001b[38;5;241m595\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/depot/schaterj/data/3d/conda-env/openpcdet_baseline/lib/python3.8/site-packages/numpy/lib/npyio.py:521\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    518\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m--> 521\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[1;32m    523\u001b[0m                        pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(fix_imports\u001b[38;5;241m=\u001b[39mfix_imports))\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (198,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# print(branch_results[500][:178])\n",
    "np.save('seq_4_slo200_ranking.npy', branch_results[200][793:991])\n",
    "np.save('seq_3_slo200_ranking.npy', branch_results[200][595:793])\n",
    "np.save('seq_2_slo200_ranking.npy', branch_results[200][397:595])\n",
    "np.save('seq_1_slo200_ranking.npy', branch_results[200][198:397])\n",
    "np.save('seq_0_slo200_ranking.npy', branch_results[200][0:198])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "\n",
    "config = 'cfgs/waymo_models/centerpoint_dyn_pillar020_1x.yaml'\n",
    "# Read the config file\n",
    "cfg_from_yaml_file(config, cfg)\n",
    "cfg.TAG = Path(config).stem\n",
    "cfg.EXP_GROUP_PATH = '/'.join(config.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "np.random.seed(1024)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "dist_test = False\n",
    "total_gpus = 1\n",
    "batch_size = 1\n",
    "workers = 4\n",
    "\n",
    "# Create logger\n",
    "logger = common_utils.create_logger()\n",
    "\n",
    "# Build the dataloader\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=batch_size,\n",
    "    dist=dist_test, workers=workers, logger=logger, training=False)\n",
    "dataset = test_loader.dataset\n",
    "class_names = dataset.class_names\n",
    "\n",
    "slo_list = (100, 125, 150, 175, 200, 225, 250, 300, 400, 500)\n",
    "# slo_list = (100, 125, 150, 175, 200, 225, 250)\n",
    "out_dir = '../output/waymo_results/oracle/own'\n",
    "for slo in tqdm(slo_list[::-1]):\n",
    "    det_path = os.path.join(out_dir, f'orin_slo{slo:d}_oracle.pkl')\n",
    "    final_output_dir = '../output/waymo_results/oracle/eval'\n",
    "    os.makedirs(final_output_dir, exist_ok=True)\n",
    "    # Read the detection results\n",
    "    print('================', det_path, '=====================')\n",
    "    det_annos = pickle.load(open(det_path, 'rb'))\n",
    "    ret_dict = {}\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "            det_annos, class_names,\n",
    "            eval_metric=cfg.MODEL.POST_PROCESSING.EVAL_METRIC,\n",
    "            output_path=final_output_dir\n",
    "        )\n",
    "\n",
    "    ret_dict.update(result_dict)\n",
    "    print(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "\n",
    "config = 'cfgs/waymo_models/centerpoint_dyn_pillar020_1x.yaml'\n",
    "# Read the config file\n",
    "cfg_from_yaml_file(config, cfg)\n",
    "cfg.TAG = Path(config).stem\n",
    "cfg.EXP_GROUP_PATH = '/'.join(config.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "np.random.seed(1024)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "dist_test = False\n",
    "total_gpus = 1\n",
    "batch_size = 1\n",
    "workers = 4\n",
    "\n",
    "# Create logger\n",
    "logger = common_utils.create_logger()\n",
    "\n",
    "# Build the dataloader\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=batch_size,\n",
    "    dist=dist_test, workers=workers, logger=logger, training=False)\n",
    "dataset = test_loader.dataset\n",
    "class_names = dataset.class_names\n",
    "\n",
    "#slo_list = (100, 150, 200, 250, 500)\n",
    "slo_list = (100, 150, 200, 250)\n",
    "out_dir = '../output/waymo_results/oracle/models'\n",
    "models = ['waymo_mse_adamw_64', 'waymo_mse_sgd_16', 'waymo_mse_sgd_64']\n",
    "for m in models:\n",
    "    for slo in tqdm(slo_list[::-1]):\n",
    "        det_path = os.path.join(out_dir, m, f'orin_slo{slo:d}_ep05.pkl')\n",
    "        final_output_dir = '../output/waymo_results/oracle/eval'\n",
    "        os.makedirs(final_output_dir, exist_ok=True)\n",
    "        # Read the detection results\n",
    "        print('================', det_path, '=====================')\n",
    "        det_annos = pickle.load(open(det_path, 'rb'))\n",
    "        ret_dict = {}\n",
    "        result_str, result_dict = dataset.evaluation(\n",
    "                det_annos, class_names,\n",
    "                eval_metric=cfg.MODEL.POST_PROCESSING.EVAL_METRIC,\n",
    "                output_path=final_output_dir\n",
    "            )\n",
    "\n",
    "        ret_dict.update(result_dict)\n",
    "        print(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.utils import common_utils\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "\n",
    "config = 'cfgs/waymo_models/centerpoint_dyn_pillar020_1x.yaml'\n",
    "# Read the config file\n",
    "cfg_from_yaml_file(config, cfg)\n",
    "cfg.TAG = Path(config).stem\n",
    "cfg.EXP_GROUP_PATH = '/'.join(config.split('/')[1:-1])  # remove 'cfgs' and 'xxxx.yaml'\n",
    "np.random.seed(1024)\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "dist_test = False\n",
    "total_gpus = 1\n",
    "batch_size = 1\n",
    "workers = 4\n",
    "\n",
    "# Create logger\n",
    "logger = common_utils.create_logger()\n",
    "\n",
    "# Build the dataloader\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=batch_size,\n",
    "    dist=dist_test, workers=workers, logger=logger, training=False)\n",
    "dataset = test_loader.dataset\n",
    "class_names = dataset.class_names\n",
    "\n",
    "slo_list = (100, 150, 200, 250, 500)\n",
    "out_dir = '../output/waymo_results/oracle/models'\n",
    "models = ['waymo_mse_adamw_64', 'waymo_mse_sgd_16', 'waymo_mse_sgd_64']\n",
    "for m in models[1:]:\n",
    "    det_path = os.path.join(out_dir, m, 'orin_slo500_ep05.pkl')\n",
    "    final_output_dir = '../output/waymo_results/oracle/eval'\n",
    "    os.makedirs(final_output_dir, exist_ok=True)\n",
    "    # Read the detection results\n",
    "    print('================', det_path, '=====================')\n",
    "    det_annos = pickle.load(open(det_path, 'rb'))\n",
    "    ret_dict = {}\n",
    "    result_str, result_dict = dataset.evaluation(\n",
    "            det_annos, class_names,\n",
    "            eval_metric=cfg.MODEL.POST_PROCESSING.EVAL_METRIC,\n",
    "            output_path=final_output_dir\n",
    "        )\n",
    "\n",
    "    ret_dict.update(result_dict)\n",
    "    print(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.6810022, 0.5048319, 0.62684095])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpc3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
